{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "model, vocab  = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_output, pooled_output = model(input_ids, input_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2461,  0.2428,  0.2590,  ..., -0.4861, -0.0731,  0.0756],\n",
       "        [-0.2478,  0.2420,  0.2552,  ..., -0.4877, -0.0727,  0.0754],\n",
       "        [-0.2472,  0.2420,  0.2561,  ..., -0.4874, -0.0733,  0.0765]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last Encoding Layer\n",
    ">>> sequence_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁한국', '어', '▁모델', '을', '▁공유', '합니다', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from gluonnlp.data import SentencepieceTokenizer\n",
    ">>> from kobert.utils import get_tokenizer\n",
    ">>> tok_path = get_tokenizer()\n",
    ">>> sp  = SentencepieceTokenizer(tok_path)\n",
    ">>> sp('한국어 모델을 공유합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁1',\n",
       " '.',\n",
       " '▁(',\n",
       " '설',\n",
       " '계',\n",
       " ')',\n",
       " '와',\n",
       " '이',\n",
       " '어',\n",
       " '링',\n",
       " '▁인',\n",
       " '출',\n",
       " '구',\n",
       " '측',\n",
       " '▁프로',\n",
       " '텍',\n",
       " '터',\n",
       " '▁최대한',\n",
       " '▁0',\n",
       " 'L',\n",
       " '측',\n",
       " '으로',\n",
       " '▁이동',\n",
       " '하여',\n",
       " '▁손',\n",
       " '간',\n",
       " '섭',\n",
       " '▁개선',\n",
       " '▁2',\n",
       " '.',\n",
       " '▁(',\n",
       " '의',\n",
       " '장',\n",
       " '51',\n",
       " '부',\n",
       " ')',\n",
       " '▁해당',\n",
       " '▁커',\n",
       " '넥',\n",
       " '터',\n",
       " '▁엔진',\n",
       " '서',\n",
       " '브',\n",
       " '반',\n",
       " '▁선',\n",
       " '작업',\n",
       " '▁가능',\n",
       " '여',\n",
       " '부',\n",
       " '▁확인',\n",
       " '요',\n",
       " '망']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sp('1. (설계)와이어링 인출구측 프로텍터 최대한 0L측으로 이동하여 손간섭 개선 2. (의장51부) 해당 커넥터 엔진서브반 선작업 가능여부 확인요망')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
