{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swpark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swpark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\swpark\\\\JupyterLab\\\\연구자료_모델예제',\n",
       " ['.ipynb_checkpoints',\n",
       "  'clustering.ipynb',\n",
       "  'collaborative_filtering.ipynb',\n",
       "  'data',\n",
       "  'decision_tree.ipynb',\n",
       "  'iris_tree_model.dot',\n",
       "  'KNN.ipynb',\n",
       "  'LDA.ipynb',\n",
       "  'logistic_regression.ipynb',\n",
       "  'similarity.ipynb',\n",
       "  'SVM.ipynb'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd(), os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**START\n",
      "-------------------------------\n",
      "Collecting bbc business news dataset\n",
      "execution time: 0:00:00.096936 \n",
      "-------------------------------\n",
      "\n",
      "-------------------------------\n",
      "Collecting bbc entertainment news dataset\n",
      "execution time: 0:00:00.066664 \n",
      "-------------------------------\n",
      "\n",
      "-------------------------------\n",
      "Collecting bbc politics news dataset\n",
      "execution time: 0:00:00.075731 \n",
      "-------------------------------\n",
      "\n",
      "-------------------------------\n",
      "Collecting bbc README.TXT news dataset\n",
      "execution time: 0:00:00 \n",
      "-------------------------------\n",
      "\n",
      "-------------------------------\n",
      "Collecting bbc sport news dataset\n",
      "execution time: 0:00:00.088593 \n",
      "-------------------------------\n",
      "\n",
      "-------------------------------\n",
      "Collecting bbc tech news dataset\n",
      "execution time: 0:00:00.069273 \n",
      "-------------------------------\n",
      "\n",
      "**END\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "print(\"**START\")\n",
    "for i, theme in enumerate(os.listdir()):\n",
    "    file_path = glob.glob(os.path.join(os.getcwd(), theme, \"*.txt\"))\n",
    "    # reading text files from each directory\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Collecting bbc {} news dataset\".format(theme))\n",
    "    start = timer()\n",
    "    for files in file_path:\n",
    "        try:\n",
    "            with open(files, \"r\", encoding=\"utf-8\") as f:\n",
    "                data.append(f.read())\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(e)\n",
    "    end = timer()\n",
    "    print(\"execution time: {} \".format(timedelta(seconds=end-start)))\n",
    "    print(\"-------------------------------\")\n",
    "    print()\n",
    "print(\"**END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225,\n",
       " 'Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\\n\\nTime Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\nTimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               contents\n",
      "0     Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
      "1     Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
      "2     Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
      "3     High fuel prices hit BA's profits\\n\\nBritish A...\n",
      "4     Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
      "...                                                 ...\n",
      "2220  BT program to beat dialler scams\\n\\nBT is intr...\n",
      "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...\n",
      "2222  Be careful how you code\\n\\nA new European dire...\n",
      "2223  US cyber security chief resigns\\n\\nThe man mak...\n",
      "2224  Losing yourself in online gaming\\n\\nOnline rol...\n",
      "\n",
      "[2225 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 그냥 나중에 편하게 쓰려고 csv 파일로 저장\n",
    "df = pd.DataFrame(data, columns = ['contents'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.getcwd()+'news_total.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [re.sub('[^a-zA-Z_]', ' ', doc) for doc in data]\n",
    "data = [re.sub('\\s+', ' ', doc) for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ad', 'sales', 'boost', 'Time', 'Warner', 'profit', 'Quarterly', 'profits', 'at', 'US', 'media', 'giant', 'TimeWarner', 'jumped', 'to', 'bn', 'm', 'for', 'the', 'three', 'months', 'to', 'December', 'from', 'm', 'year', 'earlier', 'The', 'firm', 'which']\n"
     ]
    }
   ],
   "source": [
    "tokenized_document = [word_tokenize(d) for d in data]\n",
    "print(tokenized_document[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['said', 'says', 'year', 'also', 'would', 'mr', 'bn', 'could', 'first', 'second', 'one', 'two',\n",
    "                   'use', 'used', 'last', 'time', 'make', 'new'])\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(document):\n",
    "    corpus = []\n",
    "    for d in document:\n",
    "        doc = []\n",
    "        for word in d:\n",
    "            low_word = word.lower()\n",
    "            if (low_word not in stop_words) and (len(low_word)!=1):\n",
    "                doc.append(word)\n",
    "        corpus.append(doc)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ad', 'sales', 'boost', 'Warner', 'profit', 'Quarterly', 'profits', 'US', 'media', 'giant', 'TimeWarner', 'jumped', 'three', 'months', 'December', 'earlier', 'firm', 'biggest', 'investors', 'Google', 'benefited', 'sales', 'high', 'speed', 'internet', 'connections', 'higher', 'advert', 'sales', 'TimeWarner']\n"
     ]
    }
   ],
   "source": [
    "cleaned_document = cleansing(tokenized_document)\n",
    "print(cleaned_document[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<31719 unique tokens: ['AOL', 'Ad', 'Alexander', 'Bertelsmann', 'Bros']...>\n"
     ]
    }
   ],
   "source": [
    "dict_ = corpora.Dictionary(cleaned_document)\n",
    "print(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 7), (22, 3), (23, 4), (24, 2), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 1), (50, 1), (51, 1), (52, 2), (53, 2), (54, 1), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 3), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 2), (87, 1), (88, 1), (89, 1), (90, 1), (91, 4), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 2), (119, 1), (120, 1), (121, 1), (122, 1), (123, 5), (124, 5), (125, 1), (126, 1), (127, 1), (128, 3), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 2), (135, 2), (136, 2), (137, 2), (138, 1), (139, 2), (140, 1), (141, 4), (142, 1), (143, 1), (144, 1), (145, 2), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 2), (152, 3), (153, 1), (154, 1), (155, 2), (156, 1), (157, 2), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1)]\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix = [dict_.doc2bow(i) for i in cleaned_document]\n",
    "print(doc_term_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "K = 5\n",
    "passes = 30\n",
    "iterations = 600\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, \n",
    "               num_topics=K, \n",
    "               id2word = dict_, \n",
    "               passes=passes, \n",
    "               iterations=iterations, \n",
    "               random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"people\" + 0.006*\"government\" + 0.004*\"Labour\" + 0.003*\"UK\" + 0.003*\"Blair\" + 0.003*\"told\" + 0.003*\"BBC\" + 0.003*\"public\" + 0.003*\"film\" + 0.002*\"election\"'),\n",
       " (1,\n",
       "  '0.013*\"people\" + 0.010*\"mobile\" + 0.009*\"music\" + 0.009*\"phone\" + 0.007*\"TV\" + 0.006*\"digital\" + 0.006*\"technology\" + 0.006*\"services\" + 0.006*\"service\" + 0.005*\"UK\"'),\n",
       " (2,\n",
       "  '0.007*\"games\" + 0.005*\"technology\" + 0.005*\"people\" + 0.005*\"game\" + 0.005*\"computer\" + 0.004*\"Mac\" + 0.004*\"video\" + 0.004*\"best\" + 0.004*\"PC\" + 0.004*\"show\"'),\n",
       " (3,\n",
       "  '0.005*\"US\" + 0.003*\"England\" + 0.003*\"world\" + 0.003*\"back\" + 0.003*\"win\" + 0.002*\"three\" + 0.002*\"game\" + 0.002*\"years\" + 0.002*\"company\" + 0.002*\"economy\"'),\n",
       " (4,\n",
       "  '0.006*\"software\" + 0.005*\"people\" + 0.004*\"users\" + 0.004*\"US\" + 0.004*\"net\" + 0.004*\"security\" + 0.004*\"Microsoft\" + 0.004*\"technology\" + 0.004*\"virus\" + 0.004*\"system\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
