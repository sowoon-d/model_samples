{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://velog.io/@changhtun1/Python-%EC%86%8C%EC%85%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%98-%EA%B0%90%EC%84%B1-%EC%98%88%EC%B8%A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 1  score  \\\n",
      "0           1           0      1   \n",
      "1           2           1      1   \n",
      "2           3           2      1   \n",
      "3           4           3      1   \n",
      "4           5           4      1   \n",
      "\n",
      "                                                text  \n",
      "0  메시지는 차치하고 감각적으로(시각, 청각) 황홀했다. 영화는 가능하고, 소설은 불가...  \n",
      "1  개봉일을 기다려, 모처럼 팔순의 친정어머니와 롯데 시네마에서 보았어요. 잔잔한 시냇...  \n",
      "2  하....  이것이 제 심사평입니다. 이런 게 바로 영화 아니겠습니다. 오늘 하루 ...  \n",
      "3  평양냉면 같은 영화. 막상 기대했다가 보면 이게뭐야? 할지도 모르지만 극장을 나선 ...  \n",
      "4  이 영화자체가 미나리같다. 그리고 이 영화에 나오는 인물들도 미나리같다. 특별하고 ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#warning 메시지 표시 안함\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "from konlpy.tag import Okt # 형태소 분석에 사용할 konlpy 패키지의 Okt 클래스를 임포트하고 okt 객체를 생성\n",
    "okt = Okt()\n",
    "\n",
    "# Train 데이터 불러오기\n",
    "train_df = pd.read_excel('./data/5movies.xlsx')\n",
    "\n",
    "# 데이터 확인\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14518 entries, 0 to 14517\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  14518 non-null  int64 \n",
      " 1   Unnamed: 1  14518 non-null  int64 \n",
      " 2   score       14518 non-null  int64 \n",
      " 3   text        14518 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 567.1+ KB\n",
      "None\n",
      "1    12056\n",
      "0     2462\n",
      "Name: score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 댓글이 있는 항목만 담기(빈 댓글 삭제)\n",
    "# text 컬럼이 non-null인 샘플만 train_df에 다시 저장\n",
    "train_df = train_df[train_df['text'].notnull()]\n",
    "\n",
    "# 수정된 train_df의 정보를 다시 확인\n",
    "print(train_df.info())\n",
    "\n",
    "# 분류 클래스의 구성을 확인\n",
    "print(train_df['score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 1  score  \\\n",
      "0           1           0      1   \n",
      "1           2           1      1   \n",
      "2           3           2      1   \n",
      "3           4           3      1   \n",
      "4           5           4      1   \n",
      "\n",
      "                                                text  \n",
      "0  메시지는 차치하고 감각적으로 시각  청각  황홀했다  영화는 가능하고  소설은 불가...  \n",
      "1  개봉일을 기다려  모처럼 팔순의 친정어머니와 롯데 시네마에서 보았어요  잔잔한 시냇...  \n",
      "2  하   이것이 제 심사평입니다  이런 게 바로 영화 아니겠습니다  오늘 하루 하  할듯   \n",
      "3  평양냉면 같은 영화  막상 기대했다가 보면 이게뭐야  할지도 모르지만 극장을 나선 ...  \n",
      "4  이 영화자체가 미나리같다  그리고 이 영화에 나오는 인물들도 미나리같다  특별하고 ...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14518 entries, 0 to 14517\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  14518 non-null  int64 \n",
      " 1   Unnamed: 1  14518 non-null  int64 \n",
      " 2   score       14518 non-null  int64 \n",
      " 3   text        14518 non-null  object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 567.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 한글 외 문자 제거(옵션)\n",
    "import re # 정규식을 사용하기 위해 re 모듈을 임포트\n",
    "# ‘ㄱ ~‘힣’까지의 문자를 제외한 나머지는 공백으로 치환, 영문: a-z| A-Z\n",
    "train_df['text'] = train_df['text'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "print(train_df.head())\n",
    "\n",
    "# Train용 데이터셋의 정보를 재확인\n",
    "print(train_df.info())\n",
    "text = train_df['text'] # 시리즈 객체로 저장\n",
    "score = train_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11614 11614 2904 2904\n"
     ]
    }
   ],
   "source": [
    "# Train용 데이터셋과 Test용 데이터 셋 분리\n",
    "# 1. 예측력을 높이기 위해 수집된 데이터를 학습용과 테스트 용으로 분리하여 진행\n",
    "# 2. 보통 20~30%를 테스트용으로 분리해 두고 테스트\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(text, score , test_size=0.2, random_state=0)\n",
    "print(len(train_x), len(train_y), len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8566)\t0.4911095708539604\n",
      "  (0, 5739)\t0.44604272649494614\n",
      "  (0, 943)\t0.7482361094979268\n",
      "  (1, 11344)\t0.23482722728810002\n",
      "  (1, 11342)\t0.21609487448102846\n",
      "  (1, 10945)\t0.15924591737132837\n",
      "  (1, 7708)\t0.10594727196491936\n",
      "  (1, 7052)\t0.2424948067252637\n",
      "  (1, 6929)\t0.07333685185658732\n",
      "  (1, 6889)\t0.21894416790296278\n",
      "  (1, 4795)\t0.32370407281302543\n",
      "  (1, 4794)\t0.25351062424481946\n",
      "  (1, 2974)\t0.24546132381843289\n",
      "  (1, 2610)\t0.267498217593156\n",
      "  (1, 1443)\t0.3090780150651846\n",
      "  (1, 1436)\t0.15758500675289863\n",
      "  (1, 1392)\t0.25907119332940004\n",
      "  (1, 1389)\t0.23482722728810002\n",
      "  (1, 787)\t0.3090780150651846\n",
      "  (1, 99)\t0.31565477238663886\n",
      "  (1, 72)\t0.10395613733858862\n",
      "  (2, 10335)\t0.32009352258580004\n",
      "  (2, 10334)\t0.22408433455246593\n",
      "  (2, 10059)\t0.3282560126009281\n",
      "  (2, 10003)\t0.1438288535751151\n",
      "  :\t:\n",
      "  (11613, 9288)\t0.10399109025415759\n",
      "  (11613, 8940)\t0.2159028463112065\n",
      "  (11613, 8936)\t0.18654658127862705\n",
      "  (11613, 8849)\t0.2159028463112065\n",
      "  (11613, 8647)\t0.24469418132702525\n",
      "  (11613, 8634)\t0.11837286785572594\n",
      "  (11613, 7921)\t0.18949278630654776\n",
      "  (11613, 7863)\t0.0746165785098422\n",
      "  (11613, 7714)\t0.25093396336230966\n",
      "  (11613, 7708)\t0.164259711844515\n",
      "  (11613, 6929)\t0.05685040270567615\n",
      "  (11613, 6740)\t0.25093396336230966\n",
      "  (11613, 6739)\t0.23959590818389473\n",
      "  (11613, 5286)\t0.25093396336230966\n",
      "  (11613, 5270)\t0.12753851073124342\n",
      "  (11613, 5066)\t0.18452427249019604\n",
      "  (11613, 5057)\t0.11800891801424496\n",
      "  (11613, 4025)\t0.23959590818389473\n",
      "  (11613, 3707)\t0.2159028463112065\n",
      "  (11613, 3703)\t0.16681667594971797\n",
      "  (11613, 2649)\t0.16120530428704508\n",
      "  (11613, 1616)\t0.22825785300547988\n",
      "  (11613, 837)\t0.11407978899593622\n",
      "  (11613, 484)\t0.23528537966067256\n",
      "  (11613, 72)\t0.08058633717987299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer(tokenizer=okt.morphs, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfv.fit(train_x)\n",
    "tfv_train_x = tfv.transform(train_x)\n",
    "print(tfv_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 18} 0.9133803497861118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 이진 분류 알고리즘\n",
    "from sklearn.model_selection import GridSearchCV # 하이퍼 파라미터 최적화\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "params = {'C': [15, 18, 19, 20, 22]}\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv.fit(tfv_train_x, train_y)\n",
    "\n",
    "# 최적의 평가 파라미터는 grid_cv.best_estimator_에 저장됨\n",
    "print(grid_cv.best_params_, grid_cv.best_score_)# 가장 적합한 파라메터, 최고 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분류 모델의 정확도 :  0.918\n"
     ]
    }
   ],
   "source": [
    "tfv_test_x = tfv.transform(test_x)\n",
    "# test_predict = grid_cv.best_estimator_.score(tfv_test_x,test_y)\n",
    "test_predict = grid_cv.best_estimator_.predict(tfv_test_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('감성 분류 모델의 정확도 : ',round(accuracy_score(test_y, test_predict), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1.0} 0.9001206390601014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "GNB = GaussianNB()\n",
    "GNB_params = {\"var_smoothing\":np.linspace(0.1, 1, 10)}\n",
    "grid_cv_GNB = GridSearchCV(GNB, param_grid=GNB_params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_cv_GNB.fit(tfv_train_x.todense(), train_y)\n",
    "\n",
    "# 최적의 평가 파라미터는 grid_cv.best_estimator_에 저장됨\n",
    "print(grid_cv_GNB.best_params_, grid_cv_GNB.best_score_)# 가장 적합한 파라메터, 최고 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 26.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(random_state=1),\n",
       "             param_grid=[{'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                1000.0],\n",
       "                          'kernel': ['linear']},\n",
       "                         {'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                1000.0],\n",
       "                          'gamma': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                    1000.0],\n",
       "                          'kernel': ['rbf']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "svc_params = [{'C': param_range, \n",
    "               'kernel': ['linear']},\n",
    "              {'C': param_range, \n",
    "               'gamma': param_range, \n",
    "               'kernel': ['rbf']}]\n",
    "\n",
    "svc_cv_GNB = GridSearchCV(svc_model, param_grid=svc_params, cv=3, scoring='accuracy', verbose=1)\n",
    "svc_cv_GNB.fit(tfv_train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'} 0.9157915964795794\n"
     ]
    }
   ],
   "source": [
    "# 최적의 평가 파라미터는 grid_cv.best_estimator_에 저장됨\n",
    "print(svc_cv_GNB.best_params_, svc_cv_GNB.best_score_)# 가장 적합한 파라메터, 최고 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=0), \n",
    "               {'C': [15, 18, 19, 20, 22]}))\n",
    "models.append(('GNB', GaussianNB(), \n",
    "               {\"var_smoothing\":np.linspace(0.1, 1, 10)}))\n",
    "models.append(('SVC', SVC(random_state=1), \n",
    "               {'C': param_range, \n",
    "               'gamma': param_range, \n",
    "               'kernel': ['rbf']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 192 out of 192 | elapsed: 24.5min finished\n"
     ]
    }
   ],
   "source": [
    "results_estimator = {}\n",
    "results_score = {}\n",
    "for name, model, param in models:\n",
    "    print(name)\n",
    "    gsearch = GridSearchCV(model, cv=3, param_grid=param, scoring='accuracy', verbose=1)\n",
    "    if name == 'GNB':\n",
    "        gsearch.fit(tfv_train_x.todense(), train_y)\n",
    "    else:\n",
    "        gsearch.fit(tfv_train_x, train_y)\n",
    "\n",
    "    results_estimator[name]= gsearch.best_estimator_\n",
    "    results_score[name]= gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results_score,key=results_score.get)\n",
    "best_model = results_estimator[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "filename = best_model_name + '_'+ datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.pkl'\n",
    "pickle.dump(best_model, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_predict(text):\n",
    "    #입력 텍스트에 대한 전처리 수행\n",
    "    input_text = re.compile(r'[ㄱ-ㅣ가-힣]+').findall(text)\n",
    "    input_text = [\" \".join(input_text)]\n",
    "    # 입력 텍스트의 피처 벡터화\n",
    "    st_tfidf = tfv.transform(input_text)\n",
    "\n",
    "    # 최적 감성 분석 모델에 적용하여 감성 분석 평가\n",
    "    st_predict = loaded_model.predict(st_tfidf)\n",
    "\n",
    "    #예측 결과 출력\n",
    "    if(st_predict == 0):\n",
    "        print(text, '\\n>> 예측 결과: 부정 감성')\n",
    "    else :\n",
    "        print(text, '\\n>> 예측 결과: 긍정 감성')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딱히 대단한 재미도 감동도 없는데 ~! 너무 과대 평가된 영화 중 하나 \n",
      ">> 예측 결과: 부정 감성\n",
      "돈주고 본계 아깝다 \n",
      ">> 예측 결과: 부정 감성\n",
      "이걸 왜 만든거야 \n",
      ">> 예측 결과: 부정 감성\n",
      "과연 다시볼까 내가 \n",
      ">> 예측 결과: 긍정 감성\n",
      "정말 오랜만에 재미난 영화를 본듯 \n",
      ">> 예측 결과: 긍정 감성\n",
      "우리 시간 어쩔 \n",
      ">> 예측 결과: 긍정 감성\n"
     ]
    }
   ],
   "source": [
    "text_list = ['딱히 대단한 재미도 감동도 없는데 ~! 너무 과대 평가된 영화 중 하나',\n",
    "                  '돈주고 본계 아깝다',\n",
    "                  '이걸 왜 만든거야',\n",
    "                  '과연 다시볼까 내가',\n",
    "                  '정말 오랜만에 재미난 영화를 본듯',\n",
    "                  '우리 시간 어쩔']\n",
    "for text in text_list:\n",
    "    load_model_predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
